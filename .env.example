# ===========================================
# Elvz.ai Backend - Environment Configuration
# ===========================================
# Copy this file to .env and fill in your values
# cp .env.example .env

# =====================
# Application Settings
# =====================
APP_NAME="Elvz.ai Backend"
APP_VERSION="1.0.0"
DEBUG=true
ENVIRONMENT=development

# =====================
# API Settings
# =====================
API_V1_PREFIX="/api/v1"
CORS_ORIGINS=["http://localhost:3000", "http://localhost:8000"]

# =====================
# Database (PostgreSQL)
# =====================
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DATABASE=elvz
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres
DATABASE_POOL_SIZE=20
DATABASE_MAX_OVERFLOW=10

# =====================
# Redis
# =====================
REDIS_URL=redis://localhost:6379/0
REDIS_SESSION_TTL=3600
REDIS_CACHE_TTL=21600

# =====================
# Celery (Background Tasks)
# =====================
CELERY_BROKER_URL=redis://localhost:6379/1
CELERY_RESULT_BACKEND=redis://localhost:6379/1

# =====================
# LLM Provider Selection
# =====================
# Options: "google", "openai", "anthropic"
# Set this to choose your default LLM provider
DEFAULT_LLM_PROVIDER=google

# =====================
# Google Gemini (RECOMMENDED - Set this!)
# =====================
# Get your API key from: https://makersuite.google.com/app/apikey
GOOGLE_API_KEY=your-google-gemini-api-key-here
GOOGLE_MODEL_PRIMARY=gemini-1.5-pro-latest
GOOGLE_MODEL_FAST=gemini-1.5-flash-latest

# =====================
# OpenAI (Optional - if using OpenAI)
# =====================
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=
OPENAI_MODEL_PRIMARY=gpt-4o
OPENAI_MODEL_FAST=gpt-4o-mini

# =====================
# Anthropic (Optional - if using Claude)
# =====================
# Get your API key from: https://console.anthropic.com/
ANTHROPIC_API_KEY=
ANTHROPIC_MODEL_PRIMARY=claude-3-5-sonnet-20241022

# =====================
# LLM Settings
# =====================
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=4096
LLM_TIMEOUT=60
LLM_MAX_RETRIES=3

# =====================
# Vector Database - Qdrant (Primary)
# =====================
# Production Qdrant server
QDRANT_URL=http://34.217.75.65:6333
QDRANT_API_KEY=Iz0ulVGF3zqHIiZsTOQFnbI7M69n21E3
QDRANT_COLLECTION_NAME=elvz_memory
QDRANT_VECTOR_SIZE=3072
QDRANT_DISTANCE=Cosine

# =====================
# Vector Database - Pinecone (Legacy, Optional)
# =====================
# Get your API key from: https://app.pinecone.io/
PINECONE_API_KEY=
PINECONE_ENVIRONMENT=us-east-1
PINECONE_INDEX_NAME=elvz-knowledge

# =====================
# Vector Database - Weaviate (Alternative)
# =====================
WEAVIATE_URL=http://localhost:8080
WEAVIATE_API_KEY=

# =====================
# Authentication (JWT)
# =====================
# IMPORTANT: Change this in production!
# Generate with: openssl rand -hex 32
JWT_SECRET_KEY=your-super-secret-jwt-key-change-in-production
JWT_ALGORITHM=HS256
JWT_ACCESS_TOKEN_EXPIRE_MINUTES=30
JWT_REFRESH_TOKEN_EXPIRE_DAYS=7

# =====================
# Rate Limiting
# =====================
RATE_LIMIT_REQUESTS_PER_MINUTE=60
RATE_LIMIT_TOKENS_PER_MINUTE=100000

# =====================
# External APIs (Optional)
# =====================
HASHTAG_API_KEY=
SERP_API_KEY=
GOOGLE_SEARCH_CONSOLE_KEY=

# =====================
# OpenRouter (Unified LLM Access)
# =====================
# Get your API key from: https://openrouter.ai/keys
OPENROUTER_API_KEY=your-openrouter-api-key-here
OPENROUTER_BASE_URL=https://openrouter.ai/api/v1
OPENROUTER_SITE_URL=https://elvz.ai
OPENROUTER_SITE_NAME=Elvz.ai

# =====================
# Logging
# =====================
LOG_LEVEL=INFO
LOG_FORMAT=console

# =====================
# xAI / Grok (Optional)
# =====================
XAI_API_KEY=
XAI_MODEL=grok-beta
XAI_BASE_URL=https://api.x.ai/v1

# =====================
# Firebase Storage (Optional)
# =====================
# Used for storing generated images from the visual mini-agent
FIREBASE_JSON_PATH=
FIREBASE_STORAGE_BUCKET=your-project.firebasestorage.app
FIREBASE_STORAGE_FOLDER=elvz-agent-images

# =====================
# Google Cloud / Vertex AI (Optional)
# =====================
# Required only for Vertex AI vector embeddings (alternative to Pinecone)
GOOGLE_CLOUD_PROJECT=
GOOGLE_CLOUD_LOCATION=us-central1
GOOGLE_APPLICATION_CREDENTIALS=credentials/google-service-account.json
VERTEX_EMBEDDING_MODEL=multimodalembedding@001
VERTEX_VECTOR_INDEX_ENDPOINT=
VERTEX_DEPLOYED_INDEX_ID=

# =====================
# AWS Bedrock Guardrails (Optional)
# =====================
# Enables content safety checks on user input/output.
# Falls back to keyword filtering when not configured.
# Setup: https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails.html
AWS_REGION=us-east-1
AWS_ACCESS_KEY_ID=
AWS_SECRET_ACCESS_KEY=
BEDROCK_GUARDRAIL_ID=
BEDROCK_GUARDRAIL_VERSION=DRAFT

# =====================
# LangFuse — LLM Observability (Optional)
# =====================
# Traces all LLM calls for debugging and cost monitoring.
# Get keys at: https://cloud.langfuse.com
LANGFUSE_PUBLIC_KEY=
LANGFUSE_SECRET_KEY=
LANGFUSE_HOST=https://cloud.langfuse.com

# =====================
# Sentry — Error Tracking (Optional)
# =====================
# Get DSN at: https://sentry.io
SENTRY_DSN=
SENTRY_ENVIRONMENT=development
SENTRY_TRACES_SAMPLE_RATE=0.1

# =====================
# Conversation Settings
# =====================
CONVERSATION_MAX_MESSAGES=100
CONVERSATION_CONTEXT_WINDOW=10
HITL_REQUEST_TIMEOUT_SECONDS=300

# =====================
# Memory Settings (4-layer memory system)
# =====================
MEMORY_WORKING_TTL=3600          # Working memory Redis TTL (seconds)
MEMORY_SHORT_TERM_LIMIT=50       # Max messages in short-term memory
MEMORY_RAG_TOP_K=5               # Top K results for RAG retrieval
MEMORY_TOKEN_BUDGET=6000         # Max tokens for context window

# =====================
# Query Decomposition
# =====================
MAX_PLATFORMS_PER_QUERY=3
ENABLE_PARALLEL_GENERATION=true
